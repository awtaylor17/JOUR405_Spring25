---
title: "HW11: Education Level and Survey Weighting"
author: "Your Name Here"
---

```{r setup, include=FALSE}
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
```

# Introduction

In this assignment, you'll examine how survey weighting affects our understanding of voting intentions across different education levels, using the data we examined in class. You'll calculate both weighted and unweighted statistics, create visualizations, and reflect on the implications for reporting.

## The Data

The nonvoters dataset contains survey responses about voting intentions and behaviors from a national survey. The survey was conducted prior to an election and includes demographic information like education level.

```{r}
# Load the dataset
nonvoters_data <- read_csv("https://raw.githubusercontent.com/dwillis/jour405_files/refs/heads/main/nonvoters_data.csv")

# Take a quick look at the data structure
glimpse(nonvoters_data)
```

### Key Variables

- `weight`: Survey weight assigned to each respondent
- `Q21`: Voting intention (1 = Yes, 2 = No, 3 = Unsure/Undecided)
- `educ`: Education level (College, Some college, High school or less)

## Task 1: Education Distribution

First, let's examine the distribution of education levels in our sample. Replace "REPLACE_ME" with the correct variable for education level.

```{r}

education_distribution <- nonvoters_data |>
  count(educ) |>
  mutate(percentage = n / sum(n) * 100) |>
  kable(digits = 1, col.names = c("Education Level", "Count", "Percentage (%)"))

education_distribution
```

## Task 2: Reflection Question

Why might education levels in survey samples often differ from the general population? What factors might cause certain education groups to be over or underrepresented?

Education levels in survey samples often differ from the general population because the people who have the time to answer surveys, usually have jobs that allow them the free time to do so -- and most of those jobs require a higher level of education. I would say that time is the largest factor that cause certain education groups to me underrepresented because surveys take time to respond to, and that's time someone who has to work a lot does not have. 


## Task 3: Unweighted Analysis by Education

Now, let's calculate unweighted voting intentions by education level. This is what we would report if we didn't apply any weighting to our sample.

```{r}
# Calculate unweighted voting intentions by education
unweighted_by_education <- nonvoters_data |>
  # Filter out missing values
  filter(!is.na(Q21), Q21 > 0, !is.na(educ)) |>
  # Group by education and response
  group_by(educ, Q21) |>
  # Count responses
  summarize(count = n(), .groups = "drop_last") |>
  # Calculate percentages
  mutate(total = sum(count),
         percentage = count / total * 100) |>
  ungroup()

# Create a more readable format with voting intentions as columns
unweighted_educ_summary <- unweighted_by_education |>
  pivot_wider(
    id_cols = educ,
    names_from = Q21,
    values_from = percentage,
    names_prefix = "pct_"
  ) |>
  rename(
    "Yes (%)" = pct_1,
    "No (%)" = pct_2,
    "Unsure (%)" = pct_3
  )

kable(unweighted_educ_summary, digits = 1, caption = "Unweighted Voting Intentions by Education Level")
```

## Task 4: Reflection Question

Based just on this unweighted analysis, what headline might you write for a news story about education and voting intentions?

Those with a high school education or less are least likely to vote, survey finds

## Task 5: Weighted Analysis by Education

Next, let's apply survey weights to see how this changes our results. Instead of just counting responses, we'll sum the weights for each group. Replace "REPLACE_ME" with the appropriate weight variable

```{r weighted-by-education}

weighted_by_education <- nonvoters_data |>
  # Filter out missing values
  filter(!is.na(Q21), Q21 > 0, !is.na(educ)) |>
  # Group by education and response
  group_by(educ, Q21) |>
  # Sum the weights instead of counting
  summarize(weighted_count = sum(weight), .groups = "drop_last") |>
  # Calculate weighted percentages
  mutate(weighted_total = sum(weighted_count),
         weighted_percentage = weighted_count / weighted_total * 100) |>
  ungroup()

# Create a more readable format
weighted_educ_summary <- weighted_by_education |>
  pivot_wider(
    id_cols = educ,
    names_from = Q21,
    values_from = weighted_percentage,
    names_prefix = "pct_"
  ) |>
  rename(
    "Yes (%)" = pct_1,
    "No (%)" = pct_2,
    "Unsure (%)" = pct_3
  )

kable(weighted_educ_summary, digits = 1, caption = "Weighted Voting Intentions by Education Level")
```

## Task 6: Reflection Questions

1. How did the percentages change after applying weights? Which education group showed the biggest changes?

The "College" and "Some college" groups only slightly changed after applying weights, with the "College" group changing by less than one percent. The "High school or less" group changed the most, with its largest change being about 3%.

2. Why might the weighted results be considered more accurate than the unweighted results?

The weighted results may be considered more accurate because they, ideally, better match the demographics of the population. A high proportion of people with a college degree could have been in the sample than are in the population, so weighting those people less would allow the sample to better match the distribution of each category in the population. 

## Task 7: Comparison of Weighted vs. Unweighted Results

Let's create a direct comparison table to see the differences more clearly.

```{r}

comparison <- unweighted_educ_summary |>
  inner_join(weighted_educ_summary, by = "educ", suffix = c("_unweighted", "_weighted")) |>
  mutate(
    # Calculate the differences between weighted and unweighted percentages
    yes_diff = `Yes (%)_weighted` - `Yes (%)_unweighted`,
    no_diff = `No (%)_weighted` - `No (%)_unweighted`,
    unsure_diff = `Unsure (%)_weighted` - `Unsure (%)_unweighted`
  ) |>
  # Select just the columns we want to display
  select(educ, yes_diff, no_diff, unsure_diff) |>
  rename(
    "Education Level" = educ,
    "Yes (% point diff)" = yes_diff,
    "No (% point diff)" = no_diff,
    "Unsure (% point diff)" = unsure_diff
  )

kable(comparison, digits = 1, caption = "Difference Between Weighted and Unweighted Results (percentage points)")
```

## Task 8: Reflection Question

Which education group shows the largest differences between weighted and unweighted results?

High school or less

## Task 9: Visualization

Visualizations can help us see the differences more clearly. Let's create a bar chart comparing weighted and unweighted "Yes" responses by education level. Replace "REPLACE_ME" with the correct variable name

```{r}
educ_viz_data <- bind_rows(
  # Unweighted data
  unweighted_by_education |> 
    filter(Q21 == 1) |>  # Only "Yes" responses (Q21=1)
    mutate(Type = "Unweighted") |>
    select(Type, educ, percentage),
  
  # Weighted data - 
  weighted_by_education |> 
    filter(Q21 == 1) |>  # Only "Yes" responses
    mutate(
      Type = "Weighted",
      percentage = weighted_percentage
    ) |>
    select(Type, educ, percentage)
)

# Create a grouped bar chart
ggplot(educ_viz_data, 
       aes(x = educ, y = percentage, fill = Type)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = sprintf("%.1f%%", percentage)), 
            position = position_dodge(width = 0.9), vjust = -0.5) +
  labs(
    title = "Weighted vs. Unweighted 'Yes' Responses by Education",
    subtitle = "Q21: Do you plan to vote in the November election?",
    y = "Percentage (%)",
    x = "Education Level"
  ) +
  scale_fill_manual(values = c("Unweighted" = "#619CFF", "Weighted" = "#F8766D")) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold"),
    legend.position = "bottom"
  )
```

## Task 10: Reflection Questions

Does the visualization make it easier to see the differences between weighted and unweighted results? Why or why not?

I don't believe the visualization does makes it easier to see the differences between the weighted and unweighted results. This is because the differences are hard to see on the graph, and not very evident. Unless you look very hard, both the weighted and unweighted graphs look pretty much the same. I believe displaying the numeric differences as we did in Task 7 does a much better job of conveying the difference in the weighted and unweighted results. It also makes the differences more evident. 

## Task 11: Summary

Based on your analysis of weighted and unweighted results by education level, write a brief (2-3 paragraph) journalistic summary of what you found. You should try to address:

1. How education level relates to voting intentions
2. How weighting affected your understanding of this relationship
3. What this means for interpreting polling results in news reporting

My analysis found that a higher percentage of people with higher education say they are going to vote than people with less education. This effect is increased when the results are weighted. When the data is weighted, the results for people with a college degree are increased slightly, while the results for people with some college and a high school education or less decrease, with the latter decreasing the most.

This shows that, in actuality (or closer to actuality), people with less education say they are going to vote less than the non-weighted results suggest. This means that, when interpreting poll results, journalists should take the results with a grain of salt. They should try to see if the results are weighted and if that weighting matches the demographics of the population they are looking at. 

## Task 12: Final Reflection Questions

1. Why is it important for journalists to understand survey weighting when reporting on polls?
It is important for journalists to understand survey weighting in polls because weighting can change the results of the poll. If the poll is unweighted, its results might be skewed toward people who are more likely to complete surveys and not paint an accurate picture of the population. 

2. How might the differences between weighted and unweighted results affect how you would report on this data?
For this poll, both the weighted and unweighted data still illustrate the same pattern, so it would not effect my reporting on the trend this poll shows. However, it would impact the depth of the trend, since the "high school or less" and "some college" categories both decrease when weighted. So, without the weighted data, I would still be able to tell the same general story, but I would not be able to accurately report on the scale of that trend. 

3. What additional information would you want to know about how the weights were calculated before using this data in a news story?
I would want to know what the pollster based the weights on before I used this data. Did they base if off of census data or what they personally think the weights should be? If they are basing it off of something that is fairly accurate, like census data, I would find that poll to be more trustworthy than if they based it off of a more biased analysis of the population. 
